# Data-Science-Project

School of Computer Science and Engineering

Nanyang Technological University 

Lab: A132

Team : 7

Members:

  1. Anakin Seek U2220806E
  2. Andy Chan Yan Meng U2221216B
  
--------------------------------------------------------
## Description 

This repository contains all Jupyter Notebooks, code and datasets used for the project. 

This README will cover the problem statement of our solution and will briefly cover the methodology employed in our project. 

For an in-depth breakdown of the dataset please refer to read_me.txt.

-------------------------------------------------------

## Contents

1. [File Description](https://github.com/burdenlife/Data-Science-Project/new/main?readme=1#1-file-description)
2. [Problem Statement](https://github.com/burdenlife/Data-Science-Project/new/main?readme=1#2-problem-statement)
3. [Data Cleaning](https://github.com/burdenlife/Data-Science-Project/new/main?readme=1#3-data-cleaning)
4. [Developing Models](https://github.com/burdenlife/Data-Science-Project/new/main?readme=1#4-deveoloping-models)
5. [Applying Models](https://github.com/burdenlife/Data-Science-Project/new/main?readme=1#5-applying-models)
6. [References](https://github.com/burdenlife/Data-Science-Project/new/main?readme=1#6-references)

---------------------------------------------------------

### 1. File Description

<br/>

**anime.csv**

Original dataset taken from Kaggle

<br/>

**relevant_anime_data.csv** 

Data of variables to be considered for clustering analysis.

Data was taken from anime.csv and filtered in Anime_Recommendation.ipynb

Anime that is not_yet_aired was removed from relevant_anime_data.csv as the data of these anime were not robust enough for analysis.

variables: 'anime_id', 'status', 'type', 'episodes', 'start_year', 'rating', 'source', 'genres', 'themes', 'demographics' 

<br/>

**scrape.py**

Static web scraper to obtain missing data from the original dataset.

Scrapes data from https://api.jikan.moe/v4/anime/, which is the official API for myanimelist.net

Due to the high number of queries required to run, the code takes an extremely long time to run.

In addition, the server may cut connection midway through the code running due to the high traffic volume.

While we have attempted to slow down the code by pausing between queries, this tendency still persists.

The code will periodically save progress made to temp.csv. If the code crashes, we can load temp.csv instead of relevant_data.csv to preserve progress from the previoud runtime.

<br/>

**new_anime.csv**

The final dataset used for clustering analysis and development of recommendation algorithm

Generated by scrape.py

<br/>

**Anime_Recommendation.ipynb**

Jupyter Notebook for clustering analysis of anime dataset.

The final function created takes in a list of viewed anime (by name or by id) and returns anime which are most similar

Dependencies: numpy, pandas, matplotlib, sklearn, kmodes, plotnine, lightgbm, shap, scipy

<br/>

**readme.txt**

Breakdown of data found in anime.csv

<br/>


### 2. Problem Statement

<br/>

**Dataset**: [Anime data taken from myanimelist.net](https://www.kaggle.com/datasets/andreuvallhernndez/myanimelist?select=anime.csv)

**Problem Statement**: How can anime viewers find anime they are interested in?

**Metric Used**: Similiarity between anime previously watched and recommended anime

<br/>

**Rationale**:

If a person enjoys an anime, they will likely enjoy anime which are very similar.

The type of experience an anime viewer can obtain from watching an anime can be approximated from features of the anime.

For example, animes from the same era (start_year) will have similar quality of animation, as the quality of animation has improved drastically over the years.
See read_me.txt for an in-depth breakdown of all categories chosen.

<br/>

**Reason for choosing problem**:

The members in our group all consume anime to varying degrees and felt it would be interesting to take something we intimately know as a subject for data analytics.

In addition, the nature of the project forced us to deal with clustering algorithms, something not taught in class, which proved to be an interesting learning experience.

Most importantly, the project allowed us to use our analytics for a practical purpose, which gave us a greater appreciation of the capabilities of data science as well as a greater sense of fulfillment upon completing the project.

<br/>

### 3. Data Cleaning

<br/>

The original dataset was taken from [Kaggle](https://www.kaggle.com/datasets/andreuvallhernndez/myanimelist?select=anime.csv). The dataset contains anime metadata taken from myanimelist.com.

We identified several categories of data which we determined would be of concern to anime viewers. As we are concerned with similarity of anime, we excluded factors that are universal amoung all anime like popularity and following. This is because it is absurd to expect an anime viewer to like unpopular anime in general just becasue the anime he/she enjoys happens to be unpopular.

The categories considered are:

1. episodes - as some anime viewers may not want to invest as much time into any given anime
    
2. start_year - as the era the anime was created is indicative of animation quality which drastically alters viewing experience
    
3. status - as some anime viewers do not like waiting for weekly episodes and would rather binge watch
    
4. genres/themes - indicative of the nature of the anime which is important to consider to find anime that is similar
    
5. demographics - different demographics of anime have different target audiences and tone which can alter viewing experience
    
6. source - the original work for the series may be significant for some anime viewers due to the way it shapes merchendise and the fanbase community

<br/>

We discovered Null values in various columns. Null is probable for demographics, genres and themes as an anime could feasibly have no target demographic or not contain any theme/genre that aligns with those which myanimelist has.
However, a Null value is impossible for start_year, episodes and source, as an anime cannot exist without these elements.

<br/>

Upon Analysis of the data, we discovered that majority of the problematic data were of status 'not_yet_aired'. This makes sense as an anime which has not been aired would likely have many unconfirmed elements.
Since our final product is a recommendation system, it is more user-friendly for us to remove 'not_yet_aired' anime from our dataset anyways. Thus, we decided to exclude them in our final dataset.

<br/>

For the other datapoints missing values, we attempted to query myanimelist's API for the latest values. Although the dataset was taken in 2022, the variables episodes, source and start_year are unchanging over time. 
Thus, it should not be problematic for us to take the latest data and append it to the dataset taken in 2022. The source code for the web-scraper used is found in scrape.py.

<br/>

We decided to remove datapoints that are still missing values, as they might hurt the algorithm and we deemed that there was enough datapoints to make a robust recommendation system.

<br/>
 
### 4. Developing Models

For developing our model, we considered 2 different algorithms, KMeans and KPrototypes.

<br/>

KPrototypes algorithm is suited for hybrid data which contain both categorical and numerical data and seems to be the obvious choice at first.

However, the dataset contains a list of elements for genres, demographics and themes, as an anime could reasonably have multiple values for each category.

If we were to consider each combination of genres (for example) to be an independant category, our model will not consider overlapping genres which hurts its accuracy.

<br/>

_For instance:_ 

_Take Anime A has genres ['Adventure', 'Fantasy']_

_Anime B has genres ['Adventure']_

_Anime C has genres ['Romance', 'Comedy']_

<br/>

_A will be equidistant from B and C despite sharing more common themes with B_

<br/>

Our solution was to create binary variables for each category similar to dummy coding. Each variable will essentially be a categorical variable with 2 possible categories.

  1 - Is of category , 2 - Is not of category

<br/>

However, this negatively impacts the accuracy of the KPrototypes model. 

KPrototypes includes a categorical weight component when designing its clusters. This determines how significant the variables are to be considered. 

However, our final dataset contains dozens of categories for genres, demographics and themes. This causes these categories to be more prominently represented in the clustering model, which may skew the data.

<br/>

Nevertheless, we did attempt to design clustering algorithms for both KMeans and KPrototypes before assessing which model was better for our data

<br/>

#### Step 1: Normalizing Data

Before applying the algorithm we must fist normalize the scale of each variable.

Having differently scaled variables would casue the model to be skewed as it would likely represent the larger scaled variables more.

For normalizing data we used MinMaxScaler() from the sklearn library.

<br/>

#### Step 2: Optimize Number of Clusters

Next we need to decide how many clusters is optimal for our model.

To do so, we used the Elbow Method. Basically we take the distance between each datapoint and the centre of their respective clusters. The more clusters we create, the smaller this distance will be. 

By plotting this distance against the number of clusters use, we can identify the elbow of the curve which is the ideal number of clusters.  

<br/>

#### Step 3: Visualizing and Analyzing Cluster

Lastly we need to determine the accuracy of our clusters. 

We used LGBMClassifier and cross validation score to assess the accuracy of the model.

We identified KMeans using 7 clusters as the ideal model.

<br/>

### 5. Applying Models

<br/>

After selecting our model, we can apply it to our recommendation system.

The function takes in a list of anime (by anime_id or title) that the user has watched and returns anime closest to those given by the user.

To assert the accuracy of our model, we tested just one anime to see if it would return itself.

We subsequently included checks to prevent the final output to contain any anime given as input (as it would defeat the purpose of a recommendation system).

The original function used for error checking can be accessed by setting 'testing' to 'True' for the function.

<br/>

### 6. Refrences

Anime Dataset

https://www.kaggle.com/datasets/andreuvallhernndez/myanimelist?select=anime.csv

https://api.jikan.moe/v4/anime/


Clustering Algorithms

https://towardsdatascience.com/the-k-prototype-as-clustering-algorithm-for-mixed-data-type-categorical-and-numerical-fe7c50538ebb

https://antonsruberts.github.io/kproto-audience/


KMeans

https://www.askpython.com/python/examples/plot-k-means-clusters-python

https://www.kaggle.com/code/vatsalmavani/music-recommendation-system-using-spotify-dataset/notebook



Libraries Used:

https://pypi.org/project/kmodes/

https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html

https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html

https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html

https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html

https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.cdist.html

https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMClassifier.html

https://umap-learn.readthedocs.io/en/latest/basic_usage.html

https://plotnine.readthedocs.io/en/stable/
